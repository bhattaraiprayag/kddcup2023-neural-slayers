{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a basic implementation of the LSTM model for the Task 1 using Keras and TensorFlow. Needs further work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_prod: Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
      "       'material', 'author', 'desc'],\n",
      "      dtype='object')\n",
      "train_sess: Index(['prev_items', 'next_item', 'locale'], dtype='object')\n",
      "test_sess: Index(['prev_items', 'locale'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# setting up the environment\n",
    "task = 'task1'\n",
    "train_path = './data/train/'\n",
    "test_path = './data/test/sessions_test_' + task + '.csv'\n",
    "PREDS_PER_SESSION = 100\n",
    "slice_size = 1000\n",
    "\n",
    "# slicing data for memory management\n",
    "if slice_size != None:\n",
    "    train_prod = pd.read_csv(train_path + '/products_train.csv', nrows=slice_size)\n",
    "    train_sess = pd.read_csv(train_path + '/sessions_train.csv', nrows=slice_size)\n",
    "    test_sess = pd.read_csv(test_path, nrows=slice_size)\n",
    "else:\n",
    "    train_prod = pd.read_csv(train_path + '/products_train.csv')\n",
    "    train_sess = pd.read_csv(train_path + '/sessions_train.csv')\n",
    "    test_sess = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verf√ºgbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 St√ºck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verf√ºgbar in ...  \n",
       "1  üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...  \n",
       "3  „ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 St√ºck  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        1000 non-null   object \n",
      " 1   locale    1000 non-null   object \n",
      " 2   title     1000 non-null   object \n",
      " 3   price     1000 non-null   float64\n",
      " 4   brand     981 non-null    object \n",
      " 5   color     748 non-null    object \n",
      " 6   size      572 non-null    object \n",
      " 7   model     467 non-null    object \n",
      " 8   material  576 non-null    object \n",
      " 9   author    49 non-null     object \n",
      " 10  desc      931 non-null    object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_prod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B09W9FND7K' 'B09JSPLN1M']</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items   next_item locale\n",
       "0                        ['B09W9FND7K' 'B09JSPLN1M']  B09M7GY217     DE\n",
       "1  ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...  B001B4THSA     DE\n",
       "2  ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...  B0767DTG2Q     DE\n",
       "3  ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...  B0B4R9NN4B     DE\n",
       "4           ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']  B0BGVBKWGZ     DE"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   prev_items  1000 non-null   object\n",
      " 1   next_item   1000 non-null   object\n",
      " 2   locale      1000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sess.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B08KQBYV43' '3955350843' '3955350843' '39553...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale\n",
       "0  ['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...     DE\n",
       "1           ['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']     DE\n",
       "2  ['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...     DE\n",
       "3  ['B08KQBYV43' '3955350843' '3955350843' '39553...     DE\n",
       "4  ['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...     DE"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   prev_items  1000 non-null   object\n",
      " 1   locale      1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_sess.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "# Load data\n",
    "train = train_sess\n",
    "products = train_prod\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_data = train_sess.merge(train_prod, left_on=['next_item', 'locale'], right_on=['id', 'locale'], how='left')\n",
    "\n",
    "# Tokenize 'prev_items' column\n",
    "tokenizer = Tokenizer(filters='', lower=False, split=',')\n",
    "tokenizer.fit_on_texts(merged_data['prev_items'])\n",
    "tokenized_prev_items = tokenizer.texts_to_sequences(merged_data['prev_items'])\n",
    "merged_data['prev_items'] = tokenized_prev_items\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = LabelEncoder()\n",
    "categorical_columns = ['locale', 'brand', 'color', 'size', 'model', 'material', 'author']\n",
    "for col in categorical_columns:\n",
    "    merged_data[col] = encoder.fit_transform(merged_data[col].astype(str))\n",
    "\n",
    "# Create sequences of fixed length\n",
    "sequence_length = 10\n",
    "sequences = pad_sequences(merged_data['prev_items'].values.tolist(), maxlen=sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# One-hot encode target labels separately for each categorical column\n",
    "y = merged_data[categorical_columns].apply(lambda x: to_categorical(np.array(x)))\n",
    "# y = merged_data[categorical_columns].apply(lambda x: print(x.shape) or to_categorical(x))\n",
    "# y = merged_data[categorical_columns].apply(lambda x: to_categorical(x))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(products), output_dim=128, input_length=sequence_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(categorical_columns) * len(encoder.classes_), activation='softmax'))\n",
    "model.add(Reshape((len(categorical_columns), len(encoder.classes_))))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
    "\n",
    "# Save the model\n",
    "model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = train_sess\n",
    "products = train_prod\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_data = train_sess.merge(train_prod, left_on=['next_item', 'locale'], right_on=['id', 'locale'], how='left')\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = LabelEncoder()\n",
    "categorical_columns = ['locale', 'brand', 'color', 'size', 'model', 'material', 'author']\n",
    "for col in categorical_columns:\n",
    "    merged_data[col] = encoder.fit_transform(merged_data[col].astype(str))\n",
    "\n",
    "# Normalize continuous features\n",
    "scaler = MinMaxScaler()\n",
    "merged_data['price'] = scaler.fit_transform(merged_data['price'].values.reshape(-1, 1))\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize 'prev_items' column to split the strings into lists of items\n",
    "tokenizer = Tokenizer(filters='', lower=False, split=',')\n",
    "tokenizer.fit_on_texts(merged_data['prev_items'])\n",
    "tokenized_prev_items = tokenizer.texts_to_sequences(merged_data['prev_items'])\n",
    "\n",
    "# Create sequences of fixed length\n",
    "sequence_length = 10\n",
    "sequences = pad_sequences(tokenized_prev_items, maxlen=sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(sequences, merged_data[categorical_columns], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the target variable to one-hot encoded vectors\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(products), output_dim=128, input_length=sequence_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(products), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
    "\n",
    "# Save the model\n",
    "model.save('lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
