{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Attention, Concatenate\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and clean data\n",
    "def load_and_clean_data(file_path, is_products=False, processed_file=None, slice_size=None):\n",
    "    if is_products and processed_file and os.path.exists(processed_file):\n",
    "        df = pd.read_csv(processed_file, nrows=slice_size) if slice_size else pd.read_csv(processed_file)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, nrows=slice_size) if slice_size else pd.read_csv(file_path)\n",
    "\n",
    "        if is_products:\n",
    "            # Fill missing values\n",
    "            df.fillna('unknown', inplace=True)\n",
    "\n",
    "            # Remove special characters\n",
    "            pattern = [\n",
    "                (r'<.*?>', ''),                             # Remove HTML tags\n",
    "                (r'[^\\x00-\\x7F]+', ' '),                    # Remove non-ASCII characters\n",
    "                (r'[^a-zA-Z0-9\\s]', ''),                    # Remove special characters\n",
    "                (r'\\s+', ' '),                              # Remove extra spaces\n",
    "                (r'^\\s+|\\s+?$', ''),                        # Remove leading and trailing spaces\n",
    "            ]\n",
    "\n",
    "            # Clean text\n",
    "            for col in df.select_dtypes('object').columns:\n",
    "                if col not in non_text_cols:\n",
    "                    text = df[col].str.lower()\n",
    "                    for p, r in pattern:\n",
    "                        text = text.str.replace(p, r, regex=True)\n",
    "                    df[col] = text\n",
    "\n",
    "            if processed_file and not os.path.exists(processed_file):\n",
    "                df.to_csv(processed_file, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set up environment\n",
    "task = 'task1'\n",
    "train_path = '../../data/train/'\n",
    "test_path = '../../data/test/sessions_test_' + task + '.csv'\n",
    "PREDS_PER_SESSION = 100\n",
    "slice_size = 50000                                           # Memory management, None for no slicing\n",
    "non_text_cols = ['id', 'locale', 'price']\n",
    "\n",
    "\n",
    "# Load and clean data\n",
    "processed_file = train_path + '/products_train_processed.csv'\n",
    "products_train = load_and_clean_data(train_path + '/products_train.csv', is_products=True, processed_file=processed_file, slice_size=slice_size)\n",
    "sessions_train = load_and_clean_data(train_path + '/sessions_train.csv', slice_size=slice_size)\n",
    "sessions_test = load_and_clean_data(test_path, slice_size=slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_count = {prod: sum(1 for sess in sessions_train['prev_items'] if prod in re.findall(r\"'(.*?)'\", sess)) for prod in products_train['id']}\n",
    "\n",
    "# # sort prod_count by value in descending order\n",
    "# prod_count = {k: v for k, v in sorted(prod_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "# print(prod_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       related_product  count\n",
      "14622       B07JDSHD4Z     43\n",
      "34692       B07JG9QZ2B     17\n",
      "157274      B01BVG1XJS     14\n",
      "14623       B07JG9TFSB     12\n",
      "157269      B08QYYBTMC     11\n",
      "...                ...    ...\n",
      "324995      B091YCWH9S      1\n",
      "324996      B08CRV3XXV      1\n",
      "193123      B09YD42KBD      1\n",
      "324998      B09PH91HX2      1\n",
      "423064      B09TKMQKJS      1\n",
      "\n",
      "[98 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def cooccurrence_matrix(df):\n",
    "    sessions = df['prev_items'].apply(lambda x: re.findall(r\"'(.*?)'\", x)).tolist()\n",
    "    cooccurrence = {}\n",
    "\n",
    "    for session in sessions:\n",
    "        for i in range(len(session)):\n",
    "            for j in range(i + 1, len(session)):\n",
    "                pair = tuple(sorted((session[i], session[j])))\n",
    "                if pair in cooccurrence:\n",
    "                    cooccurrence[pair] += 1\n",
    "                else:\n",
    "                    cooccurrence[pair] = 1\n",
    "\n",
    "    cooccurrence_df = pd.DataFrame(list(cooccurrence.items()), columns=['product_pair', 'count'])\n",
    "    return cooccurrence_df\n",
    "\n",
    "train_cooccurrence = cooccurrence_matrix(sessions_train)\n",
    "\n",
    "def recommend_products(product_id, cooccurrence_df, top_n=10):\n",
    "    pairs = cooccurrence_df[cooccurrence_df['product_pair'].apply(lambda x: product_id in x)]\n",
    "    pairs['related_product'] = pairs['product_pair'].apply(lambda x: x[0] if x[1] == product_id else x[1])\n",
    "    recommendations = pairs[['related_product', 'count']].sort_values(by='count', ascending=False).head(top_n)\n",
    "    return recommendations\n",
    "\n",
    "product_id = 'B07JG9TFSB'  # Replace this with the product ID you want recommendations for\n",
    "prod_to_rec = 100\n",
    "recommendations = recommend_products(product_id, train_cooccurrence, top_n=prod_to_rec)\n",
    "print(recommendations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sessions(df):\n",
    "    # using r\"'(.*?)'\" to extract the product id from the string\n",
    "    sessions = df['prev_items'].apply(lambda x: re.findall(r\"'(.*?)'\", x)).tolist()\n",
    "    return sessions\n",
    "\n",
    "train_sessions = process_sessions(sessions_train)\n",
    "\n",
    "def cooccurrence_matrix(sessions):\n",
    "    # Create an empty dictionary to store cooccurrence counts\n",
    "    cooccurrence = {}\n",
    "\n",
    "    # Iterate through the sessions\n",
    "    for session in sessions:\n",
    "        # Iterate through all possible product pairs in the session\n",
    "        for i in range(len(session)):\n",
    "            for j in range(i + 1, len(session)):\n",
    "                # Sort the product pair to ensure a consistent key\n",
    "                pair = tuple(sorted((session[i], session[j])))\n",
    "\n",
    "                # Increment the count for this product pair\n",
    "                if pair in cooccurrence:\n",
    "                    cooccurrence[pair] += 1\n",
    "                else:\n",
    "                    cooccurrence[pair] = 1\n",
    "\n",
    "    # Convert the cooccurrence dictionary to a DataFrame\n",
    "    cooccurrence_df = pd.DataFrame(list(cooccurrence.items()), columns=['product_pair', 'count'])\n",
    "\n",
    "    return cooccurrence_df\n",
    "\n",
    "train_cooccurrence = cooccurrence_matrix(train_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(product_id, cooccurrence_df, top_n=10):\n",
    "    # Find all pairs that include the target product\n",
    "    pairs = cooccurrence_df[cooccurrence_df['product_pair'].apply(lambda x: product_id in x)]\n",
    "\n",
    "    # Calculate the score for each related product\n",
    "    pairs['related_product'] = pairs['product_pair'].apply(lambda x: x[0] if x[1] == product_id else x[1])\n",
    "    pairs['score'] = pairs['count']\n",
    "\n",
    "    # Rank the related products by score and take the top N\n",
    "    recommendations = pairs[['related_product', 'score']].sort_values(by='score', ascending=False).head(top_n)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       related_product  score\n",
      "14622       B07JDSHD4Z     43\n",
      "34692       B07JG9QZ2B     17\n",
      "157274      B01BVG1XJS     14\n",
      "14623       B07JG9TFSB     12\n",
      "157269      B08QYYBTMC     11\n",
      "394226      B08V1KXBQD     10\n",
      "394225      B08V12CT4C     10\n",
      "194357      B0BHHZ9LPT      9\n",
      "157273      B099NS1XPG      8\n",
      "22569       B07T14HSNQ      7\n"
     ]
    }
   ],
   "source": [
    "product_id = 'B07JG9TFSB'  # Replace this with the product ID you want recommendations for\n",
    "prod_to_rec = 10\n",
    "recommendations = recommend_products(product_id, train_cooccurrence, top_n=prod_to_rec)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryfastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32caf6fb51a066a2a8b8a7b820a0503c974273a8c67fd79056349d1aa54cb2e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
