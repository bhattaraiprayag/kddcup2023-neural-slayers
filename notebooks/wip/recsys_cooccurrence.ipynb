{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import cProfile\n",
    "import itertools\n",
    "import pyinstrument\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import combinations\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data_processor script\n",
    "from data_processor import load_and_process_data\n",
    "\n",
    "\n",
    "# Housekeeping\n",
    "task = 'task1'\n",
    "output_path = '../../outputs/'\n",
    "final_output_file = output_path + task + '_predictions.parquet'\n",
    "prod_rec = 20\n",
    "\n",
    "\n",
    "# Memory management; set to None for full dataframe\n",
    "data_path = '../../data/'\n",
    "products_slice = 1000\n",
    "sessions_slice = 1000\n",
    "test_slice = 1000\n",
    "\n",
    "\n",
    "# Load and process data\n",
    "products_train, sessions_train, sessions_test = load_and_process_data(data_path, products_slice, sessions_slice, test_slice, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_train.shape, sessions_train.shape, sessions_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_test.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations using Co-Occurrences\n",
    "This recommendation system is based on product co-occurrence matrix. The matrix is created by analyzing the previous items purchased by customers in their sessions. The matrix is then used to recommend items that are frequently purchased together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create co-occurrence matrix\n",
    "def cooccurrence_matrix(df: pd.DataFrame) -> Tuple[csr_matrix, List[str]]:\n",
    "    sessions = df['prev_items'].apply(lambda x: x.split(',')).tolist()\n",
    "    product_to_index = {}\n",
    "    index_to_product = []\n",
    "    data, row, col = [], [], []\n",
    "\n",
    "    sorted_pairs = [tuple(sorted(pair)) for session in sessions for pair in itertools.combinations(session, 2)]\n",
    "\n",
    "    for pair in sorted_pairs:\n",
    "        for idx, product in enumerate(pair):\n",
    "            if product not in product_to_index:\n",
    "                product_to_index[product] = len(index_to_product)\n",
    "                index_to_product.append(product)\n",
    "            (row if idx == 0 else col).append(product_to_index[product])\n",
    "        data.append(1)\n",
    "\n",
    "    cooccurrence_sparse = coo_matrix((data, (row, col)), shape=(len(index_to_product), len(index_to_product))).tocsr()\n",
    "    return cooccurrence_sparse, index_to_product\n",
    "\n",
    "\n",
    "# Function to save recommendations\n",
    "def reco_saver(recommendation_function, cooccurrence_sparse: csr_matrix, index_to_product: List[str], prod_rec: int, output_path: str) -> None:\n",
    "    recos = {product_id: recommendation_function(product_id, cooccurrence_sparse, index_to_product, top_n=prod_rec).to_dict(orient='records')\n",
    "             for product_id in tqdm(index_to_product, desc=f'Saving recommendations for {len(index_to_product)} products')}\n",
    "    \n",
    "    recos_df = pd.DataFrame([(key, rec['related_product'], rec['score']) for key, records in recos.items() for rec in records], columns=['product_id', 'related_product', 'score'])\n",
    "    recos_df = recos_df.groupby('product_id').apply(lambda x: x.nlargest(prod_rec, 'score')['related_product'].tolist()).reset_index(name='next_item')\n",
    "    \n",
    "    recos_df.to_parquet(output_path)\n",
    "\n",
    "\n",
    "# Function to calculate MRR\n",
    "def mrr_from_parquet(recommendation_parquet_file: str, session_test: pd.DataFrame, prod_rec: int) -> float:\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    recos_df = pd.read_parquet(recommendation_parquet_file, engine='pyarrow')\n",
    "    recos_dict = recos_df.set_index('product_id')['next_item'].to_dict()\n",
    "\n",
    "    for _, (prev_items, ) in session_test[['prev_items']].iterrows():\n",
    "        session_products = prev_items.split(',')\n",
    "        ground_truth_product = session_products[-2] if len(session_products) > 1 else None\n",
    "        last_product = session_products[-1]\n",
    "\n",
    "        if ground_truth_product and last_product in recos_dict:\n",
    "            recommendations = list(recos_dict[last_product])\n",
    "            if ground_truth_product in recommendations:\n",
    "                rank = recommendations.index(ground_truth_product)\n",
    "                reciprocal_rank = 1 / (rank + 1)\n",
    "            else:\n",
    "                reciprocal_rank = 0\n",
    "            reciprocal_ranks.append(reciprocal_rank)\n",
    "\n",
    "    mean_reciprocal_rank = sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "    return mean_reciprocal_rank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models\n",
    "We define our model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Model 1: this one is based on the co-occurrence matrix\n",
    "def model1(product_id: str, cooccurrence_sparse: csr_matrix, index_to_product: List[str], top_n: int = 10) -> pd.DataFrame:\n",
    "    product_to_index = {product: index for index, product in enumerate(index_to_product)}\n",
    "    \n",
    "    if product_id not in product_to_index:\n",
    "        return pd.DataFrame(columns=['related_product', 'score'])\n",
    "\n",
    "    product_index = product_to_index[product_id]\n",
    "    product_scores = cooccurrence_sparse[product_index]\n",
    "    top_indices = np.argsort(-product_scores.toarray().flatten())[:top_n+1]\n",
    "\n",
    "    recommendations = pd.DataFrame({\n",
    "        'related_product': [index_to_product[i] for i in top_indices],\n",
    "        'score': product_scores[0, top_indices].toarray().flatten()\n",
    "    })\n",
    "\n",
    "    recommendations = recommendations[recommendations['related_product'] != product_id].head(top_n)\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_time = time.time()\n",
    "# Create co-occurrence matrix\n",
    "train_cooccurrence, index_to_product = cooccurrence_matrix(sessions_train)\n",
    "post_time = time.time()\n",
    "print(f'Creating co-occurrence matrix took: {post_time - pre_time:.4f} seconds')\n",
    "\n",
    "\n",
    "# Get recommendations for a single product for a specified model\n",
    "prod_id = 'B08QYYBTMC'\n",
    "model = model1\n",
    "pre_time = time.time()\n",
    "recommendations = model(prod_id, train_cooccurrence, index_to_product, top_n=prod_rec)\n",
    "post_time = time.time()\n",
    "print(f'Getting recommendations took: {post_time - pre_time:.4f} seconds')\n",
    "print(f'Top {prod_rec} recommendations for {prod_id} using {model.__name__}:')\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save recommendations to parquet file\n",
    "pre_time = time.time()\n",
    "reco_saver(model, train_cooccurrence, index_to_product, prod_rec, final_output_file)\n",
    "post_time = time.time()\n",
    "print(f'Saving recommendations took: {post_time - pre_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MRR\n",
    "pre_time = time.time()\n",
    "mrr = mrr_from_parquet(final_output_file, sessions_test, prod_rec)\n",
    "post_time = time.time()\n",
    "print(f'MRR ({model.__name__}): {mrr}')\n",
    "print(f'Calculating MRR took: {post_time - pre_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryfastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
